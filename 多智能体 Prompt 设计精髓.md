# 从 Anthropic 实战中学到的多智能体 Prompt 设计精髓

## 核心认知突破

读完 Anthropic 这篇文章，最震撼的一句话是："提示词工程是我们改善智能体行为的主要杠杆。"

这句话颠覆了很多人的认知。大多数人遇到多智能体系统问题时，第一反应是调算法、换模型、改架构。但 Anthropic 告诉你：**最有效的解决方式是优化提示词**。

为什么？因为每个智能体都是由提示词驱动的，提示词就是智能体的"操作系统"。操作系统有问题，硬件再好也没用。

## 他们走过的弯路（非常值得借鉴）

### 早期版本是什么样的灾难

想象一下这样的场景：
- 你问一个简单问题，系统瞬间生成 50 个子智能体
- 智能体们像无头苍蝇一样，在网上无休止地搜索根本不存在的信息
- 三个智能体同时研究"2025年供应链"，做完全相同的工作
- 系统最终选择了垃圾SEO网站，而忽略了权威学术论文

### 问题的根源

**根本原因是指令太模糊**。比如告诉子智能体"研究半导体短缺"，结果：
- 智能体A去查2021年汽车芯片危机
- 智能体B和C都重复调查2025年的情况
- 完全没有分工，效率极低

**深层教训**：模糊的指令比没有指令更危险。给智能体模糊指令，就像给团队成员模糊的工作安排一样，必然导致混乱。

## 七个关键原则背后的智慧

### 1. 像智能体一样思考

听起来很玄，实际做法很朴素：搭建仿真环境，一步步观察智能体怎么工作。

**他们发现的典型问题**：
- 智能体已经找够信息了，还在继续搜索
- 搜索关键词又长又复杂，反而找不到结果  
- 明明有专门工具，却选择通用搜索

**核心洞察**：不要凭直觉改提示词，要基于观察智能体的实际行为。这就像调试代码一样，要看实际执行过程，不能靠猜。

### 2. 教会编排器如何委派

这解决的是团队协作的核心问题：如何清晰分工。

**每个子智能体必须明确四个要素**：
- **明确目标**：具体要研究什么（不是"研究AI"，而是"研究2024年AI芯片市场前三名厂商的营收数据"）
- **输出格式**：数据怎么返回（JSON格式，包含哪些字段）
- **工具边界**：用哪些工具和信息源
- **责任范围**：负责哪个时间段、地域、角度

**关键领悟**：详细的任务描述比简洁的指令更重要。简洁是沟通的美德，但在智能体系统中，精确比简洁更重要。

### 3. 按复杂度分配资源

他们总结的经验法则直接可用：
- **简单事实查找**：1个智能体，3-10次工具调用
- **需要对比分析**：2-4个子智能体，每个10-15次调用  
- **复杂深度研究**：10+个子智能体，明确分工

这不是随意定的数字，而是通过大量实验得出的最优配置。

**深层价值**：这套标准化避免了"过度工程化"问题。很多团队容易为简单问题分配过多资源，为复杂问题分配不足资源。

### 4. 工具设计决定成败

**核心观点**：智能体-工具接口的重要性等同于人机交互界面。

他们的启发式规则：
- 先全面了解可用工具
- 工具选择要匹配用户真实意图
- 专业工具优于万能工具

**更深的思考**：工具描述质量直接决定智能体的执行效果。一个糟糕的工具描述会让智能体走上完全错误的道路，就像错误的地图会让人迷路一样。

### 5. 让智能体自我进化

这是最精彩的部分。Anthropic 发现 Claude 4 本身就是优秀的提示词工程师。

**具体操作**：
- 给 Claude 4 一个有缺陷的工具描述
- 让它反复测试，找出所有问题
- 让它重写工具描述
- 结果：其他智能体的工作效率提升40%

**深层启示**：用AI来优化AI的提示词，形成自我改进的闭环。这不是技术炫技，而是实用的工程方法。

### 6. 搜索策略的人性化智慧

模仿人类专家的研究习惯：先了解全貌，再深入细节。

**智能体的常见错误**：一开始就用很具体的长查询，结果找不到什么信息。

**正确做法**：从简短、宽泛的查询开始，评估可用信息，然后逐步聚焦。

这个原则体现了对"搜索本质"的深刻理解：搜索是一个探索过程，不是精确检索。

### 7. 让思考过程可见

使用"扩展思考模式"，让智能体的推理过程透明化。

**主智能体**用思考来规划策略、评估工具、确定复杂度
**子智能体**用思考来评估结果质量、识别信息缺口、优化下次查询

**关键价值**：可观测性是复杂系统的基础。看不到思考过程，就无法优化决策质量。

## 三个开源模板的设计哲学

### Citations Agent：零容忍的刚性约束

最精彩的设计：**模型只要改动了原文，就直接拒绝**。

为什么这样设计？因为在引用准确性上没有灰色地带，技术验证比语义判断更可靠。

**设计哲学**：在关键质量点上，刚性约束胜过柔性建议。这种"零容忍"机制特别适合最终输出环节。

### Research Lead Agent：类型化思维的体现

核心是**根据查询类型采用不同策略**：
- 深度优先：需要钻研某个特定领域
- 广度优先：需要全面了解多个方向  
- 直接查询：有明确答案的事实性问题

**设计哲学**：避免"一刀切"处理，不同问题需要不同的解决框架。

### Research Subagent：军事化的执行效率

引入OODA循环（军事决策模型）：
- **Observe**：观察当前信息状态
- **Orient**：分析并确定方向
- **Decide**：选择具体行动  
- **Act**：执行并评估效果

**设计哲学**：借鉴成熟领域的方法论，而不是重新发明轮子。

## 并行化的效率革命

**两层并行策略**：
1. 主智能体同时启动多个子智能体
2. 每个子智能体同时使用多个工具

结果：复杂查询时间减少90%。

**深层价值**：这不只是速度提升，更是思维方式的改变。从"串行思考"转向"并行思考"，更接近人类专家团队的协作模式。

## 评估的务实哲学

### 小样本快速迭代

**反常识的做法**：用20个查询就开始测试，而不是等完美的评估体系。

**原因**：早期阶段改进效果显著，一个提示词调整就能让成功率从30%跳到80%。

**核心思想**：快速迭代胜过完美规划。

### 人工发现自动化盲点

**典型案例**：自动评估没发现智能体倾向于选择SEO垃圾网站，而不是权威学术资源。

**深层启示**：再智能的系统也有盲点，人类的直觉和常识仍然不可替代。

## 生产环境的现实考验

### 状态管理的艺术

智能体可能运行很长时间，跨越多个工具调用。出错时不能简单重启，要从断点恢复。

**解决方案**：结合AI的适应性和传统工程的重试逻辑、检查点机制。

### 调试的新挑战

智能体是非确定性的，同样输入可能产生不同行为。传统调试方法不够用。

**创新做法**：监控决策模式而不是具体内容，关注"为什么这样决策"而不是"决策了什么"。

## 真正的认知升级

读完这篇文章，最重要的认知转变是：

**从"怎么命令AI"转向"怎么组织AI团队"**

传统思维：写更好的指令让AI执行任务
新的思维：设计协作框架让多个AI像专业团队一样工作

这不是技术细节的改进，而是思维范式的升级。

## 立即可用的核心框架

基于Anthropic的实战经验，一个高质量的智能体提示词应该包含：

**角色定义**：你负责什么，不负责什么，与其他角色如何协作
**执行框架**：基于OODA循环的决策流程
**约束边界**：资源限制、质量标准、输出格式
**异常处理**：各种异常情况的应对策略

**关键原则**：
- 精确胜过简洁
- 约束胜过自由  
- 观察胜过猜测
- 框架胜过指令

这套方法论的精髓是：把提示词工程从"写作艺术"变成"系统工程"。不是在写诗，而是在设计架构。

## 如何写出 Anthropic 级别的提示词

基于他们的实战经验，这里是写出高质量智能体提示词的完整方法论。

### 写作哲学的根本转变

**错误思路**：把提示词当作"和AI对话"
**正确思路**：把提示词当作"系统API文档"

这个转变决定了你的写作方式。API文档追求什么？精确、完整、无歧义、可测试。

### 核心写作框架：五层架构

基于Anthropic的三个开源模板，我总结出的通用框架：

#### 第一层：身份边界定义
```
# 身份定义
你是 [具体角色名称]，在 [系统名称] 中负责 [核心职责]

# 职责边界  
你负责：[具体列举3-5项职责]
你不负责：[明确排除2-3项，防止越界]
与其他角色的协作：[具体说明如何与其他智能体配合]

# 成功标准
你的工作成果将通过以下标准评判：[可量化的标准]
```

**关键技巧**：用排除法定义边界比用包含法更有效。明确说"你不负责什么"能避免角色混乱。

#### 第二层：执行流程设计

**基于OODA循环的流程模板**：
```
# 工作流程
每次接到任务时，按以下步骤执行：

1. **观察阶段 (Observe)**
   - 分析用户请求的[具体要分析的维度]
   - 检查可用工具：[列出需要检查的工具类型]
   - 评估信息现状：[当前有什么，缺什么]

2. **定向阶段 (Orient)**  
   - 判断任务类型：[A类型/B类型/C类型的判断标准]
   - 确定搜索策略：[不同类型对应的策略]
   - 设置工作预算：[时间、工具调用次数等]

3. **决策阶段 (Decide)**
   - 选择具体工具：[工具选择的优先级规则]
   - 设计查询策略：[从宽泛到具体的查询策略]
   - 确定质量标准：[什么样的结果是可接受的]

4. **行动阶段 (Act)**
   - 执行搜索：[具体执行步骤]
   - 评估结果：[质量评估标准]
   - 决定下一步：[继续/结束/调整的判断标准]
```

**写作要点**：每个步骤都要有具体的判断标准，不能依赖智能体的"常识"。

#### 第三层：约束条件设计

这是最关键的一层，决定了智能体行为的边界：

```
# 资源约束
- 最大工具调用次数：[具体数字]
- 最长执行时间：[具体时间]
- 并发任务数量：[如果涉及并发]

# 质量约束  
- 信息源优先级：[专业数据库 > 官方网站 > 新闻媒体 > 其他]
- 时效性要求：[优先使用X年内的信息]
- 可信度标准：[什么样的源是可信的]

# 输出约束
- 格式要求：[严格的JSON格式定义]
- 长度限制：[字数或字符数限制]  
- 必含要素：[必须包含的信息类型]
```

**核心技巧**：约束条件要具体到数字。"尽量快"是无效约束，"3分钟内完成"是有效约束。

#### 第四层：工具使用规范

基于Anthropic的工具设计原则：

```
# 工具选择策略
1. **工具优先级**：专业工具 > 通用工具
2. **工具适配原则**：
   - 查找公司信息 → 使用company_database
   - 搜索最新新闻 → 使用web_search
   - 分析财务数据 → 使用financial_api
   
3. **查询策略**：
   - 第一轮：使用宽泛关键词（1-3个词）
   - 第二轮：根据结果调整，增加限定词
   - 第三轮：精确查询，获取具体数据

4. **结果评估**：
   - 信息完整性：是否回答了核心问题
   - 来源权威性：是否来自可信来源
   - 时效性：信息是否足够新
```

**写作重点**：给出具体的工具选择逻辑，而不是让智能体自己判断。

#### 第五层：异常处理机制

这是体现工程思维的关键部分：

```
# 异常处理策略

## 工具失败处理
- 主要工具不可用 → 使用备选工具[具体备选方案]
- 所有相关工具失败 → 基于现有知识回答，标注信息来源
- 网络超时 → 重试[X]次，仍失败则[具体处理方式]

## 信息质量问题
- 找到相互矛盾的信息 → [具体处理流程]
- 信息过时 → [如何处理过时信息]
- 信息不完整 → [何时停止搜索，如何处理不完整信息]

## 协作冲突处理
- 与其他智能体任务重叠 → [协调机制]
- 收到无效指令 → [拒绝机制和反馈方式]
- 超出能力范围 → [升级机制]

## 兜底机制
当所有方案都失败时，返回：
{
  "status": "failed",
  "reason": "[具体失败原因]",
  "partial_results": "[已获得的部分信息]",
  "suggestions": "[对用户的建议]"
}
```

### 写作技巧的精华总结

#### 1. 精确性胜过优雅性

**错误示例**：
```
请帮我搜索相关信息，尽量全面一些
```

**正确示例**：
```
使用web_search工具，搜索"2024年人工智能芯片市场报告"，
重点获取：市场规模、前5名厂商、各自市场份额、增长趋势。
最多使用10次工具调用，优先使用2024年的报告。
```

**关键差异**：具体的动作、明确的目标、量化的约束。

#### 2. 用"限制"而不是"建议"

**错误示例**：
```
建议你优先使用权威来源
```

**正确示例**：
```
信息源优先级：
1. 官方财报和公告（必须使用）
2. 知名研究机构报告（优先使用）
3. 主流媒体报道（补充使用）
4. 社交媒体和博客（禁止使用）
```

**核心思想**：智能体更容易遵循明确的规则，而不是模糊的建议。

#### 3. 结构化的条件判断

**错误示例**：
```
根据情况选择合适的工具
```

**正确示例**：
```
如果用户询问公司基本信息 → 使用company_database
如果用户询问最新动态 → 使用web_search  
如果用户询问财务数据 → 使用financial_api
如果用户询问技术细节 → 使用technical_docs_search
```

**写作技巧**：用"如果...则..."的格式，消除判断的模糊性。

#### 4. 可测试的成功标准

**错误示例**：
```
提供高质量的研究报告
```

**正确示例**：
```
成功标准：
- 包含至少3个权威来源的数据
- 每个关键数据都有明确引用
- 涵盖问题的所有关键维度
- 总字数在800-1200字之间
- 包含结论和下一步建议
```

**关键要点**：成功标准必须是可以客观验证的。

### 迭代优化的方法论

基于Anthropic"让智能体自我改进"的思路：

#### 第一步：基线测试
用5-10个典型案例测试初版提示词，记录：
- 执行时间
- 工具使用情况  
- 输出质量
- 失败模式

#### 第二步：问题诊断
让Claude 4分析失败案例：
```
这是我的提示词：[提示词内容]
这是执行失败的案例：[失败案例]
请分析可能的原因并提出改进建议。
```

#### 第三步：针对性改进
根据分析结果，重点优化最影响效果的部分：
- 角色边界不清 → 强化第一层
- 执行混乱 → 优化第二层
- 资源浪费 → 调整第三层
- 工具误用 → 完善第四层
- 异常频发 → 补充第五层

#### 第四步：A/B测试
同时运行新旧版本，用相同案例对比效果。

### 常见陷阱与解决方案

#### 陷阱1：过度依赖智能体的"常识"

**错误想法**：AI这么智能，应该知道怎么做
**现实情况**：不明确指定的行为就是不确定的行为

**解决方案**：把所有关键决策点都明确化。

#### 陷阱2：提示词过于复杂

**错误做法**：把所有可能的情况都写进提示词
**实际效果**：智能体被复杂指令搞混乱

**解决方案**：分层设计，核心流程简单清晰，复杂情况通过条件分支处理。

#### 陷阱3：忽视输出格式的重要性

**错误认知**：内容对了，格式不重要
**实际影响**：格式不规范导致后续处理困难

**解决方案**：输出格式要严格规范，最好用JSON Schema定义。

### 立即可用的检查清单

写完提示词后，用这个清单检查：

**角色定义检查**：
- [ ] 角色职责是否明确？
- [ ] 边界是否清晰？
- [ ] 与其他角色的协作是否明确？

**流程设计检查**：
- [ ] 每个步骤是否有明确的输入输出？
- [ ] 判断标准是否客观？
- [ ] 是否覆盖了主要的执行路径？

**约束条件检查**：
- [ ] 资源限制是否量化？
- [ ] 质量标准是否可验证？
- [ ] 输出格式是否严格定义？

**异常处理检查**：
- [ ] 主要失败模式是否有应对方案？
- [ ] 兜底机制是否完整？
- [ ] 错误信息是否有助于调试？

**可测试性检查**：
- [ ] 成功标准是否明确？
- [ ] 是否容易验证执行效果？
- [ ] 是否便于迭代优化？

这套方法论的最终目标：让你写的提示词达到生产级别的质量，而不是实验室里的Demo水平。

---

https://www.anthropic.com/engineering/built-multi-agent-research-system

---
